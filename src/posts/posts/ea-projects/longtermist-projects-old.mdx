---
title: EA projects I'd like to see
slug: project-ideas-sidenotes
author: Fin Moorhouse
path: /writing/project-ideas
type: wip
subtype: misc
date: 2022-01-03
featuredImage: './project-ideas.png'
---
import Sidenote from "components/writing/sidenote";

import { Link } from "gatsby"



I think sharing half-baked ideas is an underrated practice (see my post on <Link to='../research'>research ideas</Link>). As long as sharing your idea isn't likely to do harm, of course. So I've written out some ideas for concrete projects that have been floating around my head for a while.

[Effective altruism](https://www.effectivealtruism.org/), especially [longtermism](https://longtermism.com/), has reached a point where what is most acutely needed are ideas for new, scalable, [ambitious](https://80000hours.org/articles/be-more-ambitious/) projects. Unfortunately, many of these ideas are neither especially scalable nor especially ambitious. Some are more serious than others<Sidenote label='more'>I also expect I will post a longest of less serious and smaller ideas in the future.</Sidenote>, some are only tangentially related to effective altruism. Few are entirely original, and some are me just boosting an idea I've come across.

I've arranged them from roughly most exciting to least. If you could see yourself actually working on one of these, please let me know: I might be able to connect you to other people who are also interested and could work with you. Maybe one of those people will be me.

## Funding Criticism of Effective Altruism

Tk to update for obvious reasons

Recently, some people have raised worries about how some parts of effective altruism (and/or [longtermism](https://longtermism.com/)) handles its critics, especially that these areas are too dogmatic or intellectually homogenous. This is clearly bad to the extent it is true. In fact, the perception alone that effective altruism is hostile to critics is enough for people to self-censor genuinely useful criticisms and commentaries, which is a loss.

I think one of the most valuable features of EA is its epistemic environment — I feel unusually free to discuss close to anything that seems important, and I worry an unusually small amount about offending my superiors, or saying something that could easy be taken out of context, accidentally offending my peers by disagreeing with them, or saying naive things with the aim of being corrected. I do not believe this culture is guaranteed to persist without effort to maintain it, which I think should include continuing to foster a culture of openly questioning and criticising crucial assumptions.

Beyond worries about EA being *hostile* to critics, we still might want to solicit more critical and questioning work, because:

- The set of ideas that makes up effective altruism and longtermism is still relatively new, and still being developed. It would not be surprising if the ‘consensus’ has not missed certain crucial considerations, or if some parts of that consensus were mistaken.
- Sometimes it’s possible to make mistakes in implementing a project which aren’t obvious from the inside, but can be pointed out by outside observers. This could be especially true for longtermist projects, which may have fewer obvious ‘feedback loops’.
- Points of confusion go under-reported. It can be embarrassing to announce that you're simply confused about some assumption that everyone else seems to regard as obvious. I expect there's some amount of [pluralistic ignorance](https://en.wikipedia.org/wiki/Pluralistic_ignorance) at play here, and the less of this the better.
- **The epistemic state of longtermism could be much improved.** Longtermism strikes me as an area where it may be easy to perceive more consensus and clarity than really exists. So we would be excited about suggestions about what the longtermist research community has missed so far.
  - Tk also citation trails

Clearly, no healthy social movement which wants to do good for a long time should ignore its good-faith criticism, and healthy ones should encourage them. So I would be interested in helping support more good-faith critical work relevant for effective altruism.

But *however* accurate these worries are, it is close to certain that effective altruism can benefit from constructive criticism. I would add that ['red teaming'](https://en.wikipedia.org/wiki/Red_team) is standard (and important) practice outside of the nonprofit context.



One simple suggestion to mitigate this worry is to **seek out and fund high-quality criticism** of (parts of) effective altruism.

One outcome should be to lift any atmosphere of self-censorship, to the extent that it exists. It's also obviously very bad that whenever someone does decide to offer criticism, they should [have to](https://forum.effectivealtruism.org/posts/gx7BEkoRbctjkyTme/?commentId=aT72wkJHFhgLeb4sL) "sleep, time, friends, collaborators, and mentors". Rather, as Zoe Cremer and Luke Kemp [note](https://forum.effectivealtruism.org/posts/gx7BEkoRbctjkyTme/?commentId=aT72wkJHFhgLeb4sL), "[a]cademics should never have to worry about future career prospects just because they might disagree with funders."

Another outcome should be to incentivise novel perspectives and ideas on some research paradigm that the field has so far missed. EA research often involves generalist researchers doing fast literature reviews of complex subjects, and this means important points will get glossed or missed entirely. It would be great if experts could assess the original research, and offer constructive feedback.

What exactly could this look like? Perhaps this project could offer grants for individuals to write pieces critical of some area of effective altruism. This might involve disagreeing with an influential view or piece ("I dispute X"), or it could involve engaging with a neglected perspective or discipline ("X seems to have missed Y, here's how you can add it in"). The pieces could end up in a dedicated journal, or website.

I also think this project should be sensitive to worries about losing status, prestige, or other social goods from publishing criticism. So perhaps it should be made clear by major funders that being published in this journal will not count as a mark against you (except insofar as what you say indicates that an application for funding is dishonest, of course). Where potential critics are still worried about the social consequences, it should be easy to write pseudonymously or anonymously. The [Journal of Controversial Ideas](https://journalofcontroversialideas.org/) does this.

Perhaps the trickiest question is who decides what criticism gets funded and published. Some selection would be needed, because we specifically want to reward (and so incentivise) thoughtful, useful, good faith criticism. One model is to have a board composed of insiders and outsiders to EA, who vote on applications for funding, and also decide who to proactively reach out to and offer funding. Whatever the model ends up being, it seems unusually important for the decision-making process to be transparent; meaning who was not recommended for funding should be publicly knowable (if the rejected applicant is ok with that). There should also be some means by which anyone can recommend some other person for consideration.

One final question is what should become of this critical work. I do think it would be useful to collate it all somehow, because this means that criticisms are easy to search and find. I also think it would be useful to have some means by which it's easy to identify **responses** to and **discussions** of any piece of criticism, as far as there are any. There are already [tags on the EA Forum](https://forum.effectivealtruism.org): for [criticism of effective altruist organizations](https://forum.effectivealtruism.org/tag/criticism-of-effective-altruist-organizations), [criticism of effective altruist causes](https://forum.effectivealtruism.org/tag/criticism-of-effective-altruist-causes), and [criticism of effective altruism](https://forum.effectivealtruism.org/tag/criticism-of-effective-altruism). To post criticism there would be a good start. But I expect we could do more. For instance, the project could involve a dedicated website, which lists each piece with some meta-commentary, links to discussion on the EA Forum, related pieces, and so on. It could even become a journal, although I suspect this might be jumping the gun given the absence of a journal for any part of EA itself.

## Longtermist visualisations

Imagine a ‘timeline of everything’, showing major events (astronomical, geological, historical) from the Big Bang to the end of time. Users can zoom in and out, much like existing apps that show the [scale of the universe](https://shop-us.kurzgesagt.org/products/universe-in-a-nutshell-app).

Appreciating the vast amount of time ahead of us, and the relatively brief period of time that all of recorded human history makes up, is a key underlying intuition for longtermist arguments. The website could explain longtermist ideas as link to relevant reading, like *[The Precipice](https://theprecipice.com/)*.

Various timelines of the universe have been made in video or graphic form, such as [here](https://www.youtube.com/watch?v=uD4izuDMUQA). But I suspect being able to navigate through different scales of time yourself might be a very different experience.

Ultimately, you could imagine a website hosting a series of visualizations illustrating various longtermist ideas. These visualisations and graphics, some interactive, some updated with live data, could be tied together with essays about key longtermist topics, amounting to a kind of undirected, highly visual introduction to ideas from effective altruism and longtermism. You could imagine a handful of ‘tracks’ (e.g. big history, existential risks, technological progress, human progress) which tie together these graphics, once enough are made. I am excited by the prospect of [Our World In Data](https://ourworldindata.org/) adding new charts which could be of special interest from a longtermist perspective. But I do think this project could be different enough to warrant being separate, because the visualisations could be more creative, various in form, and perhaps less squarely data-driven.

I made a small start on this idea last year, and made plans to hire for it, but left it by the wayside.

## Buying articles

If you wanted to spread ideas you thought mattered, and you happened to have [$250 million](https://www.forbes.com/sites/stephaniedenning/2018/09/19/why-jeff-bezos-bought-the-washington-post/?sh=6b0ba0c93aab) burning a hole in your pocket, you might consider buying a media company like a newspaper, such as *The Atlantic*. I expect there are far most cost-effective ways of spreading good ideas, because this strategy is so untargeted. When you buy a newspaper, you are buying all the showbiz and health and beauty columns which you can't do anything especially useful with. Your plan might be to (i) to begin taking an editorial line on certain verticals of the newspaper in the direction of the ideas you cared about, and (ii) to promote and open-access the articles that come out of (i). But buying the whole company to do this is like buying a cruise ship to execute a beach landing.

But maybe there’s a more targeted version that could work.

Some newspapers featured [sponsored articles,](https://www.theguardian.com/info/2016/jan/25/content-funding#3758127a-47fa-4242-9daf-087de11eb552) a kind of ‘native advertising’ where a company pays to either commission or write an article, which is released open-access on the newspaper’s website, along with a sticker indicating that “this post was sponsored by company X”. By 'open-access', I mean removing the paywall for that specific article.

What about a [philanthropic](https://www.theguardian.com/info/2018/oct/02/philanthropic-partnerships-at-the-guardian) version of this, where someone sponsors stories about EA topics to be published and open-accessed on popular newspapers like The Guardian or The Atlantic. Philanthropic organisations do support content on major media outlets, but I'm not aware of them paying for articles to be open-accessed. This strategy might be used to quickly spread good ideas about effective altruism.

An initial version could involve open-accessing existing articles. But you could also imagine creating an ongoing relationship with a media company where it is increasingly possible to commission articles, because the company makes more from open-accessing the ‘good’ articles than the revenue from ads they would otherwise have made.

I don’t think many articles have been ‘sponsored’ like this for philanthropic reasons, but I can’t think of why it wouldn’t be possible to do more (if not actually a good idea).

## Overlay Journal

An [overlay journal](https://en.wikipedia.org/wiki/Overlay_journal) is a journal (almost always exclusively online) that does not produce its own content, but selects from texts that are already (freely) available online. The selection process can look just like that of a ‘real’ journal, including a board of editors and peer review.

Fields within existential risk, AI safety, global priorities research, and other aspects of EA<Sidenote label='progress-journal'>Progress studies also.</Sidenote> lack dedicated journals. Yet, it’s often difficult to get such work published in decent journals because of the interdisciplinary nature of the work, because the work is unusually speculative, or because of its sheer (perceived) 'weirdness'.

That’s an issue, because research exerts influence through prestige and citations, and prestige and citations are more likely if you are published in a top journal, in part because top journals are read more.

This tentatively suggests the idea of establishing new academic journals for EA fields. But I'm not sure about that. Prestige is hard to quickly bootstrap with money, setting up a functional journal actually just sounds like a lot of hard administrative work, and any such journal would need an editorial board of prominent researchers in the field, whose time would likely be better spent doing anything other than editing a niche journal.

But maybe there is a neighbouring idea which could work: an online overlay journal, which could more quickly and easily become widely read and earn prestige or acclaim. This is because overlay journals do not compete with proper journals, but rather select from them. You could imagine the website being really attractive, and each issue could be filled with commentary from the authors and editors. Illustrations even. The product is a collection of articles designed to actually interest people in or adjacent to the field; but it is not entering the game of competing with established journals for status. 

Most overlay journals select from open-access research<Sidenote label='overlay-examples'>Such as the [*Journal of High Energy Physics*](https://en.wikipedia.org/wiki/Journal_of_High_Energy_Physics), [*Logical Methods in Computer Science*](https://en.wikipedia.org/wiki/Logical_Methods_in_Computer_Science), and [*Geometry & Topology*](https://en.wikipedia.org/wiki/Geometry_%26_Topology), which are all overlays for [arXiv](https://arxiv.org/).</Sidenote>. But I think it could also be possible to share articles from paywalled journals, by paying an '[article processing charge](https://en.wikipedia.org/wiki/Article_processing_charge)'. My (outsider) impression is that it's somewhat rare to pay to 'liberate' your article from a paywalled journal, because you can often access it for free if you belong to an academic institution which is paying a subscription to the journal, or otherwise you can use evil and nefarious means such as [Sci-Hub](https://sci-hub.hkvisa.net/). But paying to free high-quality research from their paywall silos could make sense if it meant that the research became just a bit more well-known, or easier to cite. If you think the research is really important, and you have the money to do so, then this could be a good buy<Sidenote label='overlay-sidenote'>You could definitely do this without making it part of the broader overlay journal idea.</Sidenote>.

Done well, this could help important research get eyeballs of researchers in adjacent fields, and project a certain amount of credibility. It could also provide a strong ‘worst case’ or fallback home for really good research which doesn’t have a natural home. To the extent that research is sometimes not done for this reason, or less effort is put into it, an overlay journal could incentivise quality EA research.

Take Toby Ord's recent paper ‘[*The Edges of Our Universe*](https://arxiv.org/abs/2104.01191)’. It’s valuable, fun work; and Toby was able to write it in part because he was not worrying about climbing the academic ladder with publications. It currently lives on arXiv, an open-access repository which anyone can post papers to without review. If someone more junior than Toby was considering whether to write this, it could be more likely that they decided not to.

A related idea is an open-access online magazine which *rewrites* technical work in e.g. philosophy, economics, bio, into accessible and engaging articles. [*Distil*](https://distill.pub) exemplifies how to do this for some AI research. I think I would be at least as excited about this idea as the overlay journal idea. 

## Book grantmaking

As I understand it, a lot of involved work needs to secure a book deal, and start on the process of writing the book. Before you can get an advance from one of them, you need to shop an idea around publishers, or find an outside agent you can trust to do so. The author typically needs to put a lot of their own time into this process, and in any case will need to wait before a deal goes through to begin writing with the confidence that their time is being put to good use. First-time or more obscure authors have it especially bad, since they have little to show to prospective publishers. This is presumably bad, at best because it uses up the time of people who's time is valuable and could be used just writing the book; and at worst because it makes potentially impactful books less likely to happen in the first place, for this reason.

In this new context for EA where money no longer appears to be the constraining factor, I wonder if this problem can be fixed. Imagine a group of evaluators with (i) a good amount of context on EA ideas, and (ii) a decent understanding of the world of publishing. As a prospective EA author, you apply with your book idea to this team, and if the pitch meets a basic threshold, then you quickly receive an advance. After that, the work of finding a publisher falls to this team of specialists, rather than the author herself. But the author retains the rights to the book if/when it is eventually published. If the group cannot find a publisher after some period of time, they have the option to self-publish, e.g. as a free ebook.

The major effect of such a scheme is that it would very likely **make more valuable books happen**.

Primarily, this is because the bar for which books get approved would be lower: more valuable book ideas would be quickly approved by this group than by the average publisher. The main reason the bar would be lower is that the group would not prioritise profits; up to and including the point where it could make sense to commission books which will not take a profit in expectation (but would nonetheless benefit the world as e.g. a free ebook). Another reason is that some ideas related to effective altruism might be hard to properly convey to a publisher without much context — the book could be saying something very important, and important enough that the idea could catch on and sell well, but there's a greater chance that a conventional publisher misses this. *[Superintelligence](https://www.goodreads.com/book/show/20527133-superintelligence)* might count as an example — it ended up selling surprisingly well, and this likely would have been somewhat easier to anticipate for a grantmaker with a lot of context on the ideas, versus a mainstream publisher.

The other reason this scheme might help more valuable books happen is because it just eliminates much of the administrative faff of each prospective author figuring out on their own how to get started.

When it comes to books and other media like films and social media accounts, I think a hits-based approach is best. I would guess that (i) the impact of books is roughly power-law distributed, and (ii) the expected impact of a book doesn't scale linearly with the amount of money you put into it. These two things would suggest that it would make sense to roll the dice on many book ideas which could plausibly do well.

Centrally, then, the idea is to install a middleman between EA authors and publishers, capable of smoothing out the risks for the authors by handling multiple books at once and being less sensitive than individual authors to losing money.

What's the case against? Perhaps I've overrated how much hassle it is to find a publisher in order to get started on a book. Maybe I have also overrated how many potentially very valuable EA books there are waiting to happen, but which don't happen for the reasons discussed. In particular, I might just be the case that nearly all the most promising potential authors would do better to spend their time another way, and that there aren't so many other promising potential authors.

I consider a couple additions to this idea below.

### Book marketing

There is a host of more hands-on ways to help authors produce high-quality, impactful books.

The first way is to help with **marketing and promotion**. As I understand it, publishers rarely put a lot of effort into marketing their books. More precisely, they shovel nearly all their marketing efforts into the few books they expect to perform best. So if you want to market your book properly, you really need to use a marketing agency: a firm that specialises in marketing your kind of book. But this still isn't entirely straightforward, for the familiar reason that the marketing agency might need to absorb an unusual amount of context in order to get the message dead-on. Therefore, it might be useful to have some 'in-house' marketing or promotion outfit, that interacts with established marketing agencies to generate and push on EA-specific promotion ideas. In the short-term, this should probably be a complement rather than a replacement for outside marketing agencies, because much or nearly all of the value a marketing agency offers comes from their extensive Rolodex of relationships, which is close to impossible to quickly spin up out of nothing. To pull off something more autonomous, it would probably be necessary to hire industry insiders, who could bring their contacts, expertise, and credibility.

Another way to help could be to provide **user testing** with books — sending passages or the entire book to EA volunteers for feedback. Normally it's difficult to solicit a lot of high-quality feedback while you are writing a book, but EA has the very special fortune to be made up of folks who are capable of giving useful feedback even on somewhat involved or technical pieces of writing.

### Buying back rights

Tk to do

### An EA publishing house (?)

The question that spawned these book-related thoughts was: **what if EA started a publishing house?**

I'm not *sure* this is a good aim, because It's unclear why you'd want to replace many of the functions that established publishers already serve. For instance, many publishers are well-known, and getting your book published by them counts as free credibility and publicity. And as mentioned, publishers operate through relationships which take a long time to establish.

But it would be *very cool* to have close to an end-to-end publishing operation. To begin with, this would get rid of *some* of the friction and frustration associated with grappling with an outside editor over content, cover imagery, and so on. And it would be very easy to reprint classics in the public domain, in order to bring them to a wider audience. Collected blog posts, also.

Plus, you could spin up your own badass brand, and shape it however you like. You could quickly earn [1,000 true fans](https://kk.org/thetechnium/1000-true-fans/) who automatically buy the next book you release. I think that the real impact you get from books is heavy-tailed in the sense that almost all the impact comes from a small number of readers. If you can cultivate the brand to appeal to those few readers, you don't need a very large audience to get the 'impact-adjusted reach' of a well-established publishing house.

Some people did successfully publish [some highlights](https://www.lesswrong.com/books/2018) from LessWrong, and they [just did it again](https://www.lesswrong.com/posts/mvPfao35Moah8py46/book-launch-the-engines-of-cognition). But I imagine this would have been easier, and potentially reached more people, if a specialised initiative had existed with some of the infrastructure and expertise already in place.

The obvious and standout inspiration here is the (hopefully not) inimitable [Stripe Press](https://press.stripe.com/)<Sidenote label='stripe-press'>Incidentally I think their website is the prettiest arrangement of pixels I've ever seen.</Sidenote>.

A spin on this idea could be to start an '[imprint](https://en.wikipedia.org/wiki/Imprint_(trade_name))' instead — a new 'trade name' for an existing publisher. For instance, [Viking Press](https://en.wikipedia.org/wiki/Viking_Press) is an imprint of [Penguin Random House](https://en.wikipedia.org/wiki/Penguin_Random_House).

## Book ideas

In general, I think specific book ideas aren't wildly valuable, because almost all the work, and all the value, comes from the execution rather than the idea. Regardless, here are some specific EA-relevant books I would love to read.

### A (New) Introduction to Effective Altruism

*[Doing Good Better](https://www.effectivealtruism.org/doing-good-better)* is a superb book, and probably remains the best book-length introduction to effective altruism. But because Will and the book did so much to grow EA, a consequence is that the movement has outgrown the book. This is neither a surprise nor a mark against the book — nearly 7 years have passed since it was published.

In particular, the book came before existential risks and ['longtermism'](https://longtermism.com/) really emerged as key threads in EA thinking, so the experience of reading the book and then getting up to speed with cutting-edge EA could be jarring; even confusing<Sidenote label='wwotf'>*The Precipice* and *What We Owe The Future* (forthcoming) do focus on the longtermist aspect, but they are not centrally about effective altruism the project/community/bundle of ideas.</Sidenote>. The issue isn't simply that longtermism happened — the community itself has properly grown up since 2015, along with a constellation of organisations, ideas, cause areas, and cause area candidates. If your aim is to excite people about getting involved with EA, failing to describe all the exciting stuff which has happened in the past 5 years would be to miss a wide-open goal.

So what should a new introduction to EA look like? I'm confident that it shouldn't look like a redo of *Doing Good Better* ('Doing *Doing Good Better* Better')<Sidenote label='dgb'>Although revising the book itself would be great.</Sidenote>. One cool version could be a whirlwind survey of organisations and concepts, where the aim is just to blow the reader's mind as efficiently as possible. Or it could treated like a product, where the arguments and framings are tested and developed with representative readers, and it's really optimised for a specific audience, like high school kids looking for inspiration about what to do with their lives.

I also happen to think this is unusually important to get right, since the reputation of the book would be difficult to separate from EA's overall reputation. So I think a lot of care should be taken in writing it, and likely the idea should be entrusted to someone with a track record as an ambassador.

### Utilitarianism: a Modern Introduction and Defence

I'm still a bit confused about why there are not more popular books about utilitarianism. My impression is that utilitarian views are decidedly out of vogue in the philosophical establishment. About more obscure ethical views you will find enough books, trade and academic, to fill flea markets. But the best philosophical explanation and defence of utilitarianism may literally be Mill's (1861) [*Utilitarianism*](https://www.goodreads.com/en/book/show/584637)<Sidenote label='utilitarian-books'>Here's a [list of other options](https://www.goodreads.com/shelf/show/utilitarianism). Also worthy of mention are J.J.C. Smart's *[Utilitarianism: For and Against](https://www.goodreads.com/book/show/365649.Utilitarianism)*, Peter Singer's writing (especially [*Practical Ethics*](https://www.goodreads.com/book/show/29378.Practical_Ethics)), [Katarzyna De Lazari-Radek](https://www.goodreads.com/author/show/8271243.Katarzyna_De_Lazari_Radek)'s *[Very Short Introduction](https://www.goodreads.com/book/show/34749756-utilitarianism)* and the writing of [Joshua Greene](https://www.joshua-greene.net/), especially [*Moral Tribes*](https://www.goodreads.com/book/show/17707599-moral-tribes).</Sidenote>.

I claim this is bad, and not in a way which depends on a full-blooded utilitarianism being correct. I think of 'utilitarianism' as now mostly referring to a somewhat diffuse bundle of attitudes; centrally **scope sensitivity**, **impartiality**, some kind of **aggregative principle**, a focus on **consequences**, some kind of **total view** with respect to population ethics, and some kind of **[Bayesian mindset](https://www.cold-takes.com/the-bayesian-mindset/)**. Taken independently, it just seems obviously good if more people had a better understanding of the virtues of each of these components.

I'm less interested in defending utilitarianism against edge cases and restrictions, because I think the core of the view is rarely undermined if you allow them. If most people thought the Earth was flat, and you claimed it was round, you wouldn't mind conceding that it wasn't exactly spherical.

Outside the academy, 'utilitarianism' and 'utilitarian' do not trigger positive associations, and I think it's time to reclaim those words. For instance, 'utilitarian' sounds cold and austere, but utilitarian-as-in-ethically-utilitarian design [would be really fun](https://twitter.com/AmandaAskell/status/1486790363834556422). More seriously, utilitarianism is associated with a calculating approach, as opposed to a loving one. But there's a sense in which utilitarianism is love axiomatised: the most principled way to spread and enact all the things that utilitarianism is unfavourable contrasted with.

And I'm also curious to read more thoughtful and ingenious objections, beyond the familiar ones.

### History of Philanthropy

If you're a philanthropic movement and you want to avoid the mistakes and retrace the successes of your predecessors, a good start might be learning about the history of philanthropy. So I'm pro more books that tell the story of (e.g. 20th c.) philanthropy, and which try to draw out actionable lessons from that history.

Open Philanthropy have made very good inroads on researching the [history of philanthropy](https://www.openphilanthropy.org/research/history-of-philanthropy). They report that this research "has contributed significantly to our [picture of what great giving looks like](https://www.openphilanthropy.org/research/insights-on-philanthropy)". In particular, they say that it (i) inspired ambition; (ii) suggested the value of creating rather than delegating new nonprofits; and (iii) suggested "the possibility of creating change by helping a nascent field grow even when there’s no apparent political opportunity". They also say that the most useful book they found was [*Casebook for The Foundation: A Great American Secret*](https://www.goodreads.com/book/show/10310142-casebook-for-the-foundation). I would add that *[Philanthropy: From Aristotle to Zuckerberg](https://www.goodreads.com/book/show/44452989-philanthropy)* also looks relevant.

Some people who know their stuff on this subject are [Benjamin Soskis](https://twitter.com/BenSoskis) and [Rhodri Davies](https://twitter.com/Rhodri_H_Davies). The website [HistPhil](https://histphil.org/about/) is is a web publication on the history of the philanthropic and nonprofit sectors

[Here is Stripe Press commissioning editor Tamara Winter tweeting about this question.](https://twitter.com/_TamaraWinter/status/1338978201842814976)

Beyond philanthropy, I'd also love to read a book about something like *social movements which achieved an outsized impact*. For example, the group of early [neoliberals](https://en.wikipedia.org/wiki/Neoliberalism) clustered around Chicago achieved a wild amount amount of influence, partly through the so-called '[Chicago boys](https://en.wikipedia.org/wiki/Chicago_Boys)'. How did that happen?

In a meta turn, I'd also be interested to read about the *books* that did the most to change the world, especially in a positive way. Less interested in "this famous person wrote a book, so that book must've been important", and more interested in "this book you likely haven't heard of appears to have actually influenced one or many important and consequential decisions". 

### A verbal history of EA

Effective altruism has reached a point where more people will be asking about its history, for instance to write accurate things about it. But everything happened too quickly for anyone to take notes. The records are there, but scattered across [forum](https://forum.effectivealtruism.org/) and blog posts. As EA grows, having a canonical source for the early history of EA will become more important.

But that's not the real reason I want to see a history of EA. The real reason is that it's an awesome story. It's funny, and surprising, and heartwarming, and inspiring.

One way this could get written is if a relative outsider (a journalist or writer) does some interviews, reads a few Wikipedia pages, and writes a story based on their view from the outside (like [Tom Chivers](https://www.goodreads.com/en/book/show/44154569) did for AI safety). But I am more compelled by the idea of a *verbal history* — a collection of voices woven together by an editor. [*Valley of Genius*](https://www.goodreads.com/book/show/36382335-valley-of-genius) does this for Silicon Valley and it's just epic. I hear [*Hackers*](https://www.goodreads.com/book/show/56829.Hackers) is very similar.

To be specific: imagine something like 50–150 interviews with people who were close to different parts of EA — who were in Oxford when [Giving What We Can](https://www.givingwhatwecan.org/) got started, who were around the Bay when things spread west and [80,000 Hours](https://80000hours.org/) got started, and so on. The author narrates the broad strokes at the beginning of each chapter, and 90% of the remaining text is quotes from those interviews. Strange, amusing, nerdy minutiae are appreciated.

Would such a project would be especially impactful? Not at all, as far as I can tell. Largely it would be a time-consuming exercise in naval gazery. But for the somewhat narrow audience that would appreciate such a book, I think it would be completely delightful.

### Exploring Utopia

Tk to do.

## Megaprojects idea contest

Recently, it has become feasible to entertain project ideas which could scale to absorb hundreds of millions of dollars<Sidenote label='mega project'>So-called 'megaprojects'</Sidenote>, because very large donors have stepped onto the scene and may be able to fund them. This effectively opens up a new category of project which previously was mostly not worth taking very seriously. Some ideas which could scale hugely are floating around, but there hasn't yet been a systematic push to generate and sort them.

Like an idea for a book, the idea for such a massively scalable project is maybe the easiest part — most of what matters lies in refining the ideas, and then executing them well. But ideas are also cheap, so to miss an idea for a highly impactful project of this kind would amount to an egregious missed opportunity.

One natural suggestion, then, is to announce a contest for 'megaproject' ideas. Entrances should include the case for impact, key uncertainties, and (crucially) possible harms. I'm not sure who would make a great judge, but perhaps folks with grant evaluation experience, or experienced forecasters. *Or* perhaps there is a way to have the community score the submissions. I also wonder about creative incentive models here, such as by paying submissions a bonus if the suggestion is both appreciably novel, and an appreciably similar version ends up being funded.

Are all the best 'megaproject' ideas fairly obvious? Or are some ideas, or variants on them, hiding from plain view? I'm not sure. And to the extent I'm not sure, it seems worth really checking for excellent but previously hidden ideas, especially since ideas are very cheap.

After soliciting ideas, I'd be interested in fleshing out, say, a dozen of the top proposals. Then you could imagine a round of evaluation, where perhaps teams of forecasters could independently score each proposal along various metrics, like "how many lives should we expect this to save within the next 500 years?".

## tk Something something airborne disease

Tk to do (this is just a copy paste currently)

- Here’s one way to prompt some ideas for scalable biosafety projects: after we figured out the germ theory of disease, we make big steps towards controlling and even eliminating the spread of **waterborne diseases**. For instance, we built sewage systems to sort wastewater. And we eventually developed norms and instincts about drinking only clean water, etc. What are the analogous projects for controlling and even eliminating the spread of **airborne diseases**?

- Conceptually, we can slice this up into: (i) systems for **detecting** airborne diseases, or some proxy for them; (ii) systems for **ventilating** air; and (iii) systems for **filtering** air.

- Here’s a story we could tell about a world in which technology/norms/regulations have largely curtailed the spread of airborne diseases. The country is the UK, and the year is, suppose, 2040 —

- - **Metagenomic sequencing** technology has reached the point where most businesses, schools, and public buildings are equipped with a small sequencing device, much like a carbon monoxide alarm. Perhaps most homes are also fitted with this device.

  - Air sanitation **standards** have been introduced. Government regulation mandates some minimum measure of air cleanliness, or otherwise penalises dirty air. There is therefore a larger market for filtration systems, and for ventilation systems.

  - - Perhaps there is an agreed-on measure of air quality (wrt airborne disease), like some kind of ‘ppm/concentration of pathogenic material’.
    - It could be required that new builds fully meet some additional standards — e.g. they are already fitted with a ventilation system.

  - As a consequence, much like how plumbers will fit houses to a boiler by adapting some of the plumbing, there are also **services to adapt houses for cleaner/sanitised air**; such as by installing a system of air ducts, rather than just putting a HEPA filter in the corner of a room.

  - - Initially, installing these services are subsidised.

    - Plausibly, many of the best ways to improve air quality is not through cutting-edge technology, but rather through **‘boring’ but highly scalable adaptations** and even infrastructure projects.

    - - For instance, perhaps it might eventually become possible to **access filtered air on the ‘mains’**, like how almost every home is connected to a source of natural gas and water.

    - But tying standards to the measure of cleanliness, rather than particular fixes, gives space for a **market** for different approaches, and innovation therein.

  - These ‘metagenomic detectors’ form a massive **detection network**, such that they can work as a first line of defence for alerting to novel pathogens.

  - Many homes will be surrounded by much cleaner air, such that ventilation should be a priority. But others, especially in dense urban environments, might also want to filter incoming air. These homes might employ systems similar to how **cars and aeroplanes** recycle a high throughput of air.

- How might we get there? What might intermediate stages look like?

- - Initially, **CO2 detectors might work as a good proxy** for air quality w.r.t airborne disease (because higher CO2 concentrations are likely to come from other people’s breathing).

  - - Plus, it would just generally be useful to have a world in which people are more sensitive to CO2 (and CO) concentrations, because of the effects of CO/CO2 (stuffy air) on **cognitive function**.
    - One nice common feature of having widespread air quality measurement is that people can **learn instincts and norms** around improving air quality. For instance, some people who use CO2 monitors eventually become more sensitive to when a room feels ‘stuffy’, and when a room appears poorly ventilated such that they can expect it will feel stuffy. And similar dynamics occur for blood glucose monitors and thermometers. And for becoming sensitive to touching one’s face, or shaking hands, because of Covid guidelines.

  - A major and obvious assumption here is that metagenomic sequencing technology will become **more affordable by at least a couple orders of magnitude**. But this doesn’t seem unreasonable, because (i) it’s hard to think of obvious engineering impediments, and (ii) the gap between where we are and when the tech is marketable isn’t *so* large that nobody has an incentive to work on developing it (even if the initial work will be nonprofit).

  - But there will be a point where the sequencing technology is affordable enough to be used in some government standards, but too expensive to be permanently installed in most businesses / buildings / homes. In this case, you could imagine **inspectors** who visit on the order of every couple years to take samples of air from buildings, and mandate changes (e.g. some government subsidised filtration system) if the readings are bad (analogous to fire safety inspections).

  - In order to bite, **governments** need to stand behind these standards and regulations. Is this politically viable? Plausibly. If this kind of system would just pay for itself as a public health measure, it would clearly be in a country’s interest to roll out. And there aren’t major coordination or free-rider problems.

  - - These few years after Covid could be a good period to draw up interest, given the peak in interest in preparedness/biosafety measures (and that this will probably subside in the years following). In general, it’s surprising that air filtration and ventilation has not become more widely discussed or adopted.

  - Different components could vary widely in cost. For instance, a household metagenomic sequencer or air quality monitor could cost on the order of $20–$100. But fully retrofitting a large building with filtration or ventilation could cost $10,000s. And doing things like “fitting infrastructure to have ‘clean air on the mains’ “ could cost hundreds of millions or more (though it’s very unclear if this *specific* idea would even make sense).

- Some overall reflections —

- - Some of the value of this kind of exercise is just to map the conceptual space of biosafety interventions, which can be a little illegible from the outside.

  - Many parts of this picture are likely to be wrong, but if even something like it turns out to be correct, then it seems plausible that EA could speed up adoption by around 5 years.

  - - That could involve **advocating** and **lobbying** for air quality standards;
    - And it could also involve doing the **R&D** to drive down the cost of the key technology (especially metagenomic sequencing)

## Space governance research centre

## One on one matchmaking

## Nuclear advocacy

Nuclear (fission) power is one of the most powerful, space-efficient, and scalable sources of clean energy we have. And counter to its unfortunate reputation, it is also among the [cleanest and safest](https://ourworldindata.org/safest-sources-of-energy). Unfortunately, nuclear power is way underused compared to its promise, especially in rich Western countries. I think it's hard to overstate how bad this is — if we're serious about majorly transitioning to clean energy, it looks like nuclear is close to necessary.

As far as I see it, this is largely a product of (i) unhelpful regulation around nuclear power R&D; and (ii) public opinion, which still seems attached to images of glowing green goo, and a certain HBO [miniseries](https://www.hbo.com/chernobyl). With a really concerted effort of just getting credible information into the open, I think it's possible to change these things, especially the latter. Someone who is killing it at advocating for nuclear power in a really creative way is the inimitable [Isabelle Boemeke](https://www.highsnobiety.com/p/isabelle-boemeke-interview/).

<Sidenote label='fusion'>And then there's fusion — it looks like private money is beginning to flood into fusion research now, and we're seeing [results](https://www.bbc.com/news/science-environment-60312633) from public and private research alike. In fact, my guess is that a small lab will get to [ignition](https://en.wikipedia.org/wiki/Fusion_ignition) before [ITER](https://en.wikipedia.org/wiki/ITER), the decabillion-Euro international fusion project. Working fusion would be incredible, but it's easy to overlook the more immediately useful R&D frontier of [small modular fission reactors](https://en.wikipedia.org/wiki/Small_modular_reactor), which promise a way to get more nuclear power onto the grid in less time and at less expense — two major barriers to investment in nuclear.</Sidenote>

One idea a big, concerted effort at making nuclear's reputation less toxic, for instance by supporting science communicators to make a bunch of educational videos. Another idea is to set up a political advocacy group, perhaps even a PAC in the US, to come up with really sensible policy change to make it easier and more attractive to develop more and cheaper nuclear power. There's a long way to go — some countries seem to be losing nuclear power plants on net, by [decommissioning](https://abcnews.go.com/International/wireStory/correction-germany-nuclear-shutdown-story-82051054) [some of them](https://en.wikipedia.org/wiki/Diablo_Canyon_Power_Plant).

Why would this be good? Shifting away from dirty energy should obviously be a priority, for reasons I don't need to elaborate on. From a [longtermist](https://longtermism.com/) perspective, keeping fossil fuels in the ground could make it more likely that civilisations recover from a collapse to pre-industrial levels of technology.

There's also increasing our supply of 

Something something growth

## Spoken word content

Tk noting that I think these extra ideas could come later... I guess also could separate out the more fun ideas.

- Utopia exploration (best-cases)
- Something nuclear?
- Whistleblower refuge and incentives
- Cybersecurity
- Web design agency
- Something about [tech trees](https://forum.effectivealtruism.org/posts/ckcoSe3CS2n3BW3aT/what-ea-projects-could-grow-to-become-megaprojects?commentId=cHjwxHdsmj4YSknh6)?
- EA debates
- Something about therapy for EAs?
- Impact certificates! Of course
- Also quadratic funding for EAs
- PDF/better academic formatting! / better version of ArXiV.
- High school competitions like FLL
- EA wins ledger
  - https://repository.upenn.edu/cgi/viewcontent.cgi?article=1019&context=think_tanks&fbclid=IwAR0xgmwZ6lxo_9ued53s5ZgNQIl9oyImmQeYwaLZI5hsIpxpzR1LOA8Ruq4




Maybe there could be a part 1

Tk to decide on case haha

Reflections on sharing